{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear programming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5, 30)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as pl\n",
    "import numpy as np\n",
    "h1=np.arange(-2.,30.)\n",
    "# definimos espacio de parametros posibles\n",
    "#constraint 1  -2x1+x2< 2\n",
    "c1=(600-h1*60)/10\n",
    "fig, ax = pl.subplots()\n",
    "pl.plot(h1,c1,'r',label='condition 1')\n",
    "#constraint 2  x1 < 3\n",
    "pl.axvline(x=24)\n",
    "pl.axhline(y=24)\n",
    "#constraint 3  -x1+x2<=3\n",
    "c3=(400-30*h1)/10\n",
    "pl.plot(h1,c3,'g',label='condition 2')\n",
    "#contraint  4   x1,x2>0\n",
    "pl.axhline(y=0)\n",
    "pl.axvline(x=0)\n",
    "c4=(1000-40*h1)/60\n",
    "pl.plot(h1,c4,'y',label='condition 3')\n",
    "#pl.ylim(-1,7)\n",
    "pl.xlabel(r'$h_1$')\n",
    "pl.ylabel(r'$h_2$')\n",
    "\n",
    "h1=np.arange(6.,25.)\n",
    "c3=(400.-30*h1)/10\n",
    "c1=(600.-h1*60)/10\n",
    "c4=(1000.-40*h1)/60\n",
    "#c3=3+x1\n",
    "#c1=(2*x1+2)\n",
    "c5=h1*0+12\n",
    "y4 = np.maximum(c1, c3)\n",
    "y5 = np.maximum(c4, y4)\n",
    "#y6 = np.maximum(y5, h1*0+24)\n",
    "\n",
    "ax.fill_between(h1,y5,24)\n",
    "pl.legend()\n",
    "h1=np.arange(-2.,30.)\n",
    "# objective 1.80*h1+1.6*h2\n",
    "pl.plot(h1,(60-5.*h1)/1.6,'k--')\n",
    "pl.plot(h1,(50-5.*h1)/1.6,'k--')\n",
    "pl.plot(h1,(20-5.*h1)/1.6,'k--')\n",
    "\n",
    "pl.xlim(0,30)\n",
    "pl.ylim(-5,30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function linprog in module scipy.optimize._linprog:\n",
      "\n",
      "linprog(c, A_ub=None, b_ub=None, A_eq=None, b_eq=None, bounds=None, method='simplex', callback=None, options=None)\n",
      "    Minimize a linear objective function subject to linear\n",
      "    equality and inequality constraints.\n",
      "    \n",
      "    Linear Programming is intended to solve the following problem form::\n",
      "    \n",
      "        Minimize:     c^T * x\n",
      "    \n",
      "        Subject to:   A_ub * x <= b_ub\n",
      "                      A_eq * x == b_eq\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    c : array_like\n",
      "        Coefficients of the linear objective function to be minimized.\n",
      "    A_ub : array_like, optional\n",
      "        2-D array which, when matrix-multiplied by ``x``, gives the values of\n",
      "        the upper-bound inequality constraints at ``x``.\n",
      "    b_ub : array_like, optional\n",
      "        1-D array of values representing the upper-bound of each inequality\n",
      "        constraint (row) in ``A_ub``.\n",
      "    A_eq : array_like, optional\n",
      "        2-D array which, when matrix-multiplied by ``x``, gives the values of\n",
      "        the equality constraints at ``x``.\n",
      "    b_eq : array_like, optional\n",
      "        1-D array of values representing the RHS of each equality constraint\n",
      "        (row) in ``A_eq``.\n",
      "    bounds : sequence, optional\n",
      "        ``(min, max)`` pairs for each element in ``x``, defining\n",
      "        the bounds on that parameter. Use None for one of ``min`` or\n",
      "        ``max`` when there is no bound in that direction. By default\n",
      "        bounds are ``(0, None)`` (non-negative)\n",
      "        If a sequence containing a single tuple is provided, then ``min`` and\n",
      "        ``max`` will be applied to all variables in the problem.\n",
      "    method : str, optional\n",
      "        Type of solver.  :ref:`'simplex' <optimize.linprog-simplex>`\n",
      "        and :ref:`'interior-point' <optimize.linprog-interior-point>`\n",
      "        are supported.\n",
      "    callback : callable, optional (simplex only)\n",
      "        If a callback function is provide, it will be called within each\n",
      "        iteration of the simplex algorithm. The callback must have the\n",
      "        signature ``callback(xk, **kwargs)`` where ``xk`` is the current\n",
      "        solution vector and ``kwargs`` is a dictionary containing the\n",
      "        following::\n",
      "    \n",
      "            \"tableau\" : The current Simplex algorithm tableau\n",
      "            \"nit\" : The current iteration.\n",
      "            \"pivot\" : The pivot (row, column) used for the next iteration.\n",
      "            \"phase\" : Whether the algorithm is in Phase 1 or Phase 2.\n",
      "            \"basis\" : The indices of the columns of the basic variables.\n",
      "    \n",
      "    options : dict, optional\n",
      "        A dictionary of solver options. All methods accept the following\n",
      "        generic options:\n",
      "    \n",
      "            maxiter : int\n",
      "                Maximum number of iterations to perform.\n",
      "            disp : bool\n",
      "                Set to True to print convergence messages.\n",
      "    \n",
      "        For method-specific options, see :func:`show_options('linprog')`.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    A `scipy.optimize.OptimizeResult` consisting of the following fields:\n",
      "    \n",
      "        x : ndarray\n",
      "            The independent variable vector which optimizes the linear\n",
      "            programming problem.\n",
      "        fun : float\n",
      "            Value of the objective function.\n",
      "        slack : ndarray\n",
      "            The values of the slack variables.  Each slack variable corresponds\n",
      "            to an inequality constraint.  If the slack is zero, then the\n",
      "            corresponding constraint is active.\n",
      "        success : bool\n",
      "            Returns True if the algorithm succeeded in finding an optimal\n",
      "            solution.\n",
      "        status : int\n",
      "            An integer representing the exit status of the optimization::\n",
      "    \n",
      "                 0 : Optimization terminated successfully\n",
      "                 1 : Iteration limit reached\n",
      "                 2 : Problem appears to be infeasible\n",
      "                 3 : Problem appears to be unbounded\n",
      "    \n",
      "        nit : int\n",
      "            The number of iterations performed.\n",
      "        message : str\n",
      "            A string descriptor of the exit status of the optimization.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    show_options : Additional options accepted by the solvers\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    This section describes the available solvers that can be selected by the\n",
      "    'method' parameter. The default method\n",
      "    is :ref:`Simplex <optimize.linprog-simplex>`.\n",
      "    :ref:`Interior point <optimize.linprog-interior-point>` is also available.\n",
      "    \n",
      "    Method *simplex* uses the simplex algorithm (as it relates to linear\n",
      "    programming, NOT the Nelder-Mead simplex) [1]_, [2]_. This algorithm\n",
      "    should be reasonably reliable and fast for small problems.\n",
      "    \n",
      "    .. versionadded:: 0.15.0\n",
      "    \n",
      "    Method *interior-point* uses the primal-dual path following algorithm\n",
      "    as outlined in [4]_. This algorithm is intended to provide a faster\n",
      "    and more reliable alternative to *simplex*, especially for large,\n",
      "    sparse problems. Note, however, that the solution returned may be slightly\n",
      "    less accurate than that of the simplex method and may not correspond with a\n",
      "    vertex of the polytope defined by the constraints.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] Dantzig, George B., Linear programming and extensions. Rand\n",
      "           Corporation Research Study Princeton Univ. Press, Princeton, NJ,\n",
      "           1963\n",
      "    .. [2] Hillier, S.H. and Lieberman, G.J. (1995), \"Introduction to\n",
      "           Mathematical Programming\", McGraw-Hill, Chapter 4.\n",
      "    .. [3] Bland, Robert G. New finite pivoting rules for the simplex method.\n",
      "           Mathematics of Operations Research (2), 1977: pp. 103-107.\n",
      "    .. [4] Andersen, Erling D., and Knud D. Andersen. \"The MOSEK interior point\n",
      "           optimizer for linear programming: an implementation of the\n",
      "           homogeneous algorithm.\" High performance optimization. Springer US,\n",
      "           2000. 197-232.\n",
      "    .. [5] Andersen, Erling D. \"Finding all linearly dependent rows in\n",
      "           large-scale linear programming.\" Optimization Methods and Software\n",
      "           6.3 (1995): 219-227.\n",
      "    .. [6] Freund, Robert M. \"Primal-Dual Interior-Point Methods for Linear\n",
      "           Programming based on Newton's Method.\" Unpublished Course Notes,\n",
      "           March 2004. Available 2/25/2017 at\n",
      "           https://ocw.mit.edu/courses/sloan-school-of-management/15-084j-nonlinear-programming-spring-2004/lecture-notes/lec14_int_pt_mthd.pdf\n",
      "    .. [7] Fourer, Robert. \"Solving Linear Programs by Interior-Point Methods.\"\n",
      "           Unpublished Course Notes, August 26, 2005. Available 2/25/2017 at\n",
      "           http://www.4er.org/CourseNotes/Book%20B/B-III.pdf\n",
      "    .. [8] Andersen, Erling D., and Knud D. Andersen. \"Presolving in linear\n",
      "           programming.\" Mathematical Programming 71.2 (1995): 221-245.\n",
      "    .. [9] Bertsimas, Dimitris, and J. Tsitsiklis. \"Introduction to linear\n",
      "           programming.\" Athena Scientific 1 (1997): 997.\n",
      "    .. [10] Andersen, Erling D., et al. Implementation of interior point\n",
      "            methods for large scale linear programming. HEC/Universite de\n",
      "            Geneve, 1996.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Consider the following problem:\n",
      "    \n",
      "    Minimize: f = -1*x[0] + 4*x[1]\n",
      "    \n",
      "    Subject to: -3*x[0] + 1*x[1] <= 6\n",
      "                 1*x[0] + 2*x[1] <= 4\n",
      "                            x[1] >= -3\n",
      "    \n",
      "    where:  -inf <= x[0] <= inf\n",
      "    \n",
      "    This problem deviates from the standard linear programming problem.\n",
      "    In standard form, linear programming problems assume the variables x are\n",
      "    non-negative.  Since the variables don't have standard bounds where\n",
      "    0 <= x <= inf, the bounds of the variables must be explicitly set.\n",
      "    \n",
      "    There are two upper-bound constraints, which can be expressed as\n",
      "    \n",
      "    dot(A_ub, x) <= b_ub\n",
      "    \n",
      "    The input for this problem is as follows:\n",
      "    \n",
      "    >>> c = [-1, 4]\n",
      "    >>> A = [[-3, 1], [1, 2]]\n",
      "    >>> b = [6, 4]\n",
      "    >>> x0_bounds = (None, None)\n",
      "    >>> x1_bounds = (-3, None)\n",
      "    >>> from scipy.optimize import linprog\n",
      "    >>> res = linprog(c, A_ub=A, b_ub=b, bounds=(x0_bounds, x1_bounds),\n",
      "    ...               options={\"disp\": True})\n",
      "    Optimization terminated successfully.\n",
      "         Current function value: -22.000000\n",
      "         Iterations: 1\n",
      "    >>> print(res)\n",
      "         fun: -22.0\n",
      "     message: 'Optimization terminated successfully.'\n",
      "         nit: 1\n",
      "       slack: array([39.,  0.])\n",
      "      status: 0\n",
      "     success: True\n",
      "           x: array([10., -3.])\n",
      "    \n",
      "    Note the actual objective value is 11.428571.  In this case we minimized\n",
      "    the negative of the objective function.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import linprog\n",
    "help(linprog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=[20,6]  # ponemos coeficientes de función objetivo\n",
    "A_ub=[[-60,-10],[-30,-10],[-40,-60]]         # ponemos equaciones en forma de matriz. Fila 1, coeficientes eq 1\n",
    "               #                                        Fila 2, coeficientes eq 2 ...\n",
    "b_ub=[-600,-400,-1000]        # Fila 1 resultado inecuacion 1\n",
    "               # Fila 2 resultado inecuación 2\n",
    "# A_eq,b_eq    lo mismo para igualdades, en este caso no hay\n",
    "bounds=(0,24)      # valores maximos y minimos que toma cada variable. Si son distintos [(0,24),(0,12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=linprog(c,A_ub=A_ub,b_ub=b_ub,bounds=bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resolvemos con python. \n",
    "Resolvemos con \"trust-constr\" que poner las ecuaciones en un objeto \n",
    "LinearConstraint(A, lb, ub)  donde lb <= A.dot(x) <= ub. A tiene dimension num variables = 2 x numero de inequaciones en este caso 2, el resto vendrá definido en bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 6.66666667, 20.        ]), 253.33333333333334)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.x,res.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return -2*x[0]*x[1]+x[1]**2\n",
    "def jac(x):\n",
    "    return [-2*x[1],2*x[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`xtol` termination condition is satisfied.\n",
      "Number of iterations: 385, function evaluations: 427, CG iterations: 544, optimality: 1.03e+01, constraint violation: 2.16e+00, execution time: 0.85 s.\n"
     ]
    }
   ],
   "source": [
    "import scipy.optimize as opt\n",
    "from scipy.optimize import Bounds\n",
    "from scipy.optimize import LinearConstraint\n",
    "def func(x):\n",
    "    return -2*x[0]*x[1]+x[1]**2\n",
    "def Jac(x):\n",
    "    return [-2*x[1],2*x[1]]\n",
    "\n",
    "bounds=((0,None),(0,3))\n",
    "#lb=[None,None]\n",
    "ub=[2,3]\n",
    "A=[[-2,1],[-1,1]]\n",
    "#bounds=Bounds([0,0],[24,24])\n",
    "lb=[-np.inf,-np.inf]\n",
    "#ub=[2,3]\n",
    "#A=[[-2,1],[-1,1]]\n",
    "LinCons=LinearConstraint(A,lb,ub)\n",
    "\n",
    "res = opt.minimize(func, [0,0], method='trust-constr', jac=Jac,hess='3-point',constraints=LinCons,options={'verbose': 1}, bounds=bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.311021021179527e+29\n",
      "[2.23914129e+28 5.16050736e+00]\n"
     ]
    }
   ],
   "source": [
    "print res.fun\n",
    "print res.x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PUNTO función es mínima [17.68  7.56] valor Función -210.0\n"
     ]
    }
   ],
   "source": [
    "print 'PUNTO función es mínima',np.round(res.x,2),'valor Función',np.round(res.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# si tenemos equacion no-Lineal  con las mismas inequaciones, lo mismo, tenemos que recalcular el gradiente\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
